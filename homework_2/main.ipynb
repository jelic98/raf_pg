{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PG - Domaci 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLwcyQmLuq9S"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "from sys import exit\n",
        "from IPython.display import Audio"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhpxEsW99aA2"
      },
      "source": [
        "path_sample = '/content/drive/My Drive/Colab Notebooks/PG/data/male/1.wav' #input(\"WAV path: \")\n",
        "path_templates = '/content/templates.txt' #input(\"Templates path: \")\n",
        "\n",
        "p = 50 #int(input(\"Endpointing P: \"))\n",
        "q = 10 #int(input(\"Endpointing Q: \"))\n",
        "\n",
        "coef_fun = 'mfcc' #input(\"Coefficients (lpcc, mfcc): \")\n",
        "\n",
        "lpcc_len = 13 #int(input(\"LPCC length: \"))\n",
        "\n",
        "window_fun = 'hanning' #input(\"Windowing function (hanning, hamming, none): \")\n",
        "window_len = 2048 #int(input(\"Window length: \"))\n",
        "hop_size = 100 #int(input(\"Hop size: \"))\n",
        "filter_num = 10 #int(input(\"Total filters: \"))\n",
        "mfcc_len = 13 #int(input(\"MFCC length: \"))\n",
        "mfcc_delta = True #True if input(\"Use MFCC delta parameters (yes, no): \") == 'yes' else False\n",
        "mfcc_tau = 3 #int(input(\"MFCC tau: \"))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kToh9Q9aXhNw"
      },
      "source": [
        "templates = load_templates(path_templates)\n",
        "data, rate = load_wav(path_sample)\n",
        "samples = apply_endpointing(data, rate, p, q)\n",
        "\n",
        "for i, s in enumerate(samples):\n",
        "    play_wav(s, rate)\n",
        "    name = input(\"Sample #{} name: \".format(i+1))\n",
        "    lpcc, mfcc = apply_coding(s, rate, 'lpcc').tolist(), apply_coding(s, rate, 'mfcc').tolist()\n",
        "    templates.append({'name': name, 'lpcc': lpcc, 'mfcc': mfcc})\n",
        "\n",
        "save_templates(path_templates, templates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHzo9NBqq6C"
      },
      "source": [
        "templates = load_templates(path_templates)\n",
        "data, rate = load_wav(path_sample)\n",
        "samples = apply_endpointing(data, rate, p, q)\n",
        "\n",
        "for i, s in enumerate(samples):\n",
        "    coefs = apply_coding(s, rate, coef_fun)\n",
        "    matches = sorted([(t['name'], apply_dtw(coefs, np.array(t[coef_fun]))) for t in templates], key = lambda x: x[1])\n",
        "    print(\"Sample #{}\".format(i+1))\n",
        "    for t, dtw in matches:\n",
        "        if dtw > 0:\n",
        "            print(\"Match: ({})\\t{}\".format(dtw, t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVMb08IaqCTi"
      },
      "source": [
        "def load_wav(path):\n",
        "    raw = wf.read(path)\n",
        "    return raw[1], raw[0]\n",
        "\n",
        "\n",
        "def play_wav(data, rate):\n",
        "    display(Audio(data, rate=rate))\n",
        "\n",
        "\n",
        "def load_templates(path):\n",
        "    try:\n",
        "        with open(path, 'r') as fd:\n",
        "            return json.load(fd)\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "\n",
        "def save_templates(path, templates):\n",
        "    with open(path, 'w') as fd:\n",
        "        json.dump(templates, fd, indent=4)\n",
        "\n",
        "\n",
        "def create_scaffolds(windows, curr, sub, length):\n",
        "    i, lmt = 0, len(windows)\n",
        "    \n",
        "    if windows[-1] != sub:\n",
        "        windows.append(sub)\n",
        "        lmt -= 1\n",
        "    \n",
        "    scaffolds = []\n",
        "\n",
        "    while i < lmt:\n",
        "        if windows[i] == curr:\n",
        "            j = windows.index(sub, i + 1)\n",
        "            if j - i < length:\n",
        "                windows[i:j] = [sub] * (j - i)\n",
        "            else:\n",
        "                scaffolds.append((i, j))\n",
        "            i = j\n",
        "        i += 1\n",
        "    \n",
        "    return scaffolds\n",
        "\n",
        "\n",
        "def apply_endpointing(data, rate, p, q):\n",
        "    dur_noise, dur_window = 0.1, 0.01\n",
        "    n_noise, n_window = int(rate * dur_noise), int(rate * dur_window)\n",
        "    \n",
        "    noise = np.abs(data[:n_noise])\n",
        "    lmt = np.mean(noise) + 2 * np.std(noise)\n",
        "\n",
        "    windows = [1 if np.mean(np.abs(data[i:i+n_window])) > lmt else 0 for i in range(0, len(data), n_window)]\n",
        "    create_scaffolds(windows, 0, 1, p)\n",
        "    \n",
        "    scaffolds = create_scaffolds(windows, 1, 0, q)\n",
        "    \n",
        "    if len(scaffolds) == 0:\n",
        "        sys.exit(\"Error: Only silence detected\")\n",
        "    \n",
        "    return [data[i*n_window:j*n_window] for i, j in scaffolds]\n",
        "\n",
        "\n",
        "def apply_slicing(data, rate, window_len, hop_size):\n",
        "    data = np.pad(data, window_len // 2, mode='reflect')\n",
        "\n",
        "    frame_len = rate * hop_size // 1000\n",
        "    frame_num = (data.shape[0] - window_len) // frame_len + 1\n",
        "    \n",
        "    return np.array([data[i*frame_len:i*frame_len+window_len] for i in range(frame_num)])\n",
        "\n",
        "\n",
        "def apply_windowing(data, rate, fun, size):\n",
        "    funs = {'hanning': np.hanning, 'hamming': np.hamming, 'none': np.ones}\n",
        "    for i in range(data.shape[0]):\n",
        "        data[i] *= funs[fun](data[i].shape[0])\n",
        "    return data\n",
        "\n",
        "\n",
        "def apply_dft(data, window_len):\n",
        "    data_dft = np.empty((1 + window_len // 2, data.shape[0]), dtype=np.complex64)\n",
        "\n",
        "    for i in range(data_dft.shape[1]):\n",
        "        data_dft[:, i] = np.fft.fft(data[i])[:data_dft.shape[0]]\n",
        "\n",
        "    return np.square(np.abs(data_dft))\n",
        "\n",
        "\n",
        "def freq_to_mel(freq):\n",
        "    return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
        "\n",
        "\n",
        "def mel_to_freq(mels):\n",
        "    return 700.0 * (10.0**(mels / 2595.0) - 1.0)\n",
        "\n",
        "\n",
        "def get_filter_points(rate, filter_num, window_len):\n",
        "    mel_min, mel_max = freq_to_mel(0), freq_to_mel(rate // 2)\n",
        "\n",
        "    freqs = mel_to_freq(np.linspace(mel_min, mel_max, filter_num + 2))\n",
        "    points = np.floor((window_len + 1) / rate * freqs).astype(int)\n",
        "\n",
        "    return points, freqs\n",
        "\n",
        "\n",
        "def get_filters(filter_points, window_len):\n",
        "    filter_num = filter_points.shape[0] - 2\n",
        "    filters = np.zeros((filter_num, window_len // 2 + 1))\n",
        "\n",
        "    for i in range(filter_num):\n",
        "        prev, curr, next = filter_points[i], filter_points[i+1], filter_points[i+2]\n",
        "        filters[i, prev:curr] = np.linspace(0, 1, curr - prev)\n",
        "        filters[i, curr:next] = np.linspace(1, 0, next - curr)\n",
        "\n",
        "    return filters\n",
        "\n",
        "\n",
        "def apply_filters(data, filter_num, window_len):\n",
        "    filter_points, mel_freqs = get_filter_points(rate, filter_num, window_len)\n",
        "    filters = get_filters(filter_points, window_len)\n",
        "\n",
        "    enorm = 2.0 / (mel_freqs[2:filter_num+2] - mel_freqs[:filter_num])\n",
        "    filters *= enorm[:, np.newaxis]\n",
        "\n",
        "    return np.dot(filters, data)\n",
        "\n",
        "\n",
        "def apply_dct(data, filter_num, filter_len):\n",
        "    samples = np.arange(1, 2 * filter_len, 2) * np.pi / (2.0 * filter_len)\n",
        "\n",
        "    filters = np.empty((filter_num, filter_len))\n",
        "    filters[0] = 1.0 / np.sqrt(filter_len)\n",
        "    filters[1:] = [np.cos(i * samples) * np.sqrt(2.0 / filter_len) for i in range(1, filter_num)]\n",
        "\n",
        "    return np.dot(filters, 10.0 * np.log10(data))\n",
        "\n",
        "\n",
        "def get_lpcc(data, rate, lpcc_len):\n",
        "    data = data / np.max(np.abs(data))\n",
        "\n",
        "    data_slices = apply_slicing(data, rate, window_len, hop_size)\n",
        "    data_windows = apply_windowing(data_slices, rate, window_fun, window_len)\n",
        "\n",
        "    lpcc = np.empty((data_windows.shape[0], lpcc_len))\n",
        "\n",
        "    for i, w in enumerate(data_windows):\n",
        "        r = [sum(s[n] * s[n-k] for n in range(k, w.shape[0])) for k in range(lpcc_len)]\n",
        "        r_mat = [[r[abs(i-j)] for i in range(lpcc_len)] for j in range(lpcc_len)]\n",
        "        lpcc[i] = np.dot(np.linalg.inv(r_mat), r)\n",
        "\n",
        "    return lpcc\n",
        "\n",
        "def get_mfcc(data, rate, mfcc_len, filter_num, add_delta=False, tau=None):\n",
        "    data = data / np.max(np.abs(data))\n",
        "\n",
        "    data_slices = apply_slicing(data, rate, window_len, hop_size)\n",
        "    data_windows = apply_windowing(data_slices, rate, window_fun, window_len)\n",
        "    data_dft = apply_dft(data_windows, window_len)\n",
        "    data_filtered = apply_filters(data_dft, filter_num, window_len)\n",
        "    mfcc = apply_dct(data_filtered, mfcc_len, filter_num)\n",
        "\n",
        "    # TODO\n",
        "    if add_delta:\n",
        "        for window in mfcc:\n",
        "            delta1 = []\n",
        "            for i in range(tau, mfcc.shape[1] - tau):\n",
        "                delta1.append(window[i+tau]-window[i-tau])\n",
        "            np.append(window, delta1)\n",
        "\n",
        "    return np.transpose(mfcc)\n",
        "\n",
        "\n",
        "def apply_coding(data, rate, coef):\n",
        "    if coef == 'lpcc':\n",
        "        return get_lpcc(data, rate, lpcc_len)\n",
        "    elif coef == 'mfcc':\n",
        "        return get_mfcc(data, rate, mfcc_len, filter_num, mfcc_delta, mfcc_tau)\n",
        "    else:\n",
        "        sys.exit(\"Error: Invalid coefficients\")\n",
        "\n",
        "\n",
        "def apply_dtw(s, t):\n",
        "    n, m = s.shape[0], t.shape[0]\n",
        "\n",
        "    dtw = np.full((n, m), np.inf)\n",
        "    dtw[0, 0] = 0\n",
        "    \n",
        "    for i in range(1, n):\n",
        "        for j in range(1, m):\n",
        "            curr = np.linalg.norm(s[i] - t[j])\n",
        "            prev = np.min([dtw[i-1, j], dtw[i, j-1], dtw[i-1, j-1]])\n",
        "            dtw[i, j] = prev + curr\n",
        "\n",
        "    return dtw[n-1, m-1]"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}